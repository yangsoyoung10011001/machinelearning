# -*- coding: utf-8 -*-
"""3d.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17nvhVVdlj-61YeKhsIcPpvyWXCfN1RiS
"""

!pip install pyclustering

from matplotlib import pyplot as plt
from sklearn.metrics import accuracy_score
import pandas as pd
import numpy as np
from sklearn import preprocessing
import warnings ; warnings.filterwarnings('ignore')
import seaborn as sns
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score
from sklearn import preprocessing
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
import sys
from sklearn.metrics import silhouette_score
from matplotlib import pyplot as plt
from pyclustering.cluster.clarans import clarans
from mpl_toolkits.mplot3d import Axes3D

df = pd.read_csv('/content/drive/MyDrive/머신러닝/housing.csv')
# print(df.dtypes)
# print(df.isna().sum())

##setting data set
# separate median house value feature
mhv=df['median_house_value']
df.drop('median_house_value',axis=1, inplace=True)
# fill nan value in total_bedrooms
df.fillna(0, inplace=True)


roomDF=df[['total_rooms', 'total_bedrooms']]
whereDF=df[['longitude', 'latitude', 'ocean_proximity']]
specDF=df[['housing_median_age', 'total_rooms', 'total_bedrooms', 'ocean_proximity']]
enviDF=df[['population', 'households']]

sc=preprocessing.StandardScaler()
enc=preprocessing.OrdinalEncoder()

op=enc.fit_transform(whereDF['ocean_proximity'].to_numpy().reshape(-1, 1))
whereDF['ocean_proximity']=op
tdf=whereDF[0:20000]
print(tdf['ocean_proximity'].groupby(tdf['ocean_proximity']).count())
# tdf=tdf.drop('ocean_proximity', axis=1)
print(tdf)
tdfs=sc.fit_transform(tdf)
tdfs=tdfs.tolist()

# need dataframe, list of label, number of clusters
def makePlt23(df, label, k):
    # list for store feature data for each cluster
    store = [[[] for col in range(len(df.columns))] for row in range(k)]

    for m in range(len(label)):
        for n in range(k):
            if(label[m]==n):
                for o in range(len(df.columns)):
                    store[n][o].append(df.iloc[m:m+1, o:o+1].values[0][0])

    c = ['b.', 'r.', 'g.', 'y.', 'c.', 'm.']
    if(len(df.columns)==2):
        plt.subplot(230 + (k - 1))
        plt.xlabel(df.columns[0])
        plt.ylabel(df.columns[1])
        for p in range(k):
            plt.plot(store[p][0], store[p][1], c[p])
    if(len(df.columns)==3):
        plt.subplot(230+(k-1), projection='3d')
        plt.xlabel(df.columns[0])
        plt.ylabel(df.columns[1])
        for p in range(k):
            plt.plot(store[p][0], store[p][1], store[p][2], c[p])


########## clarans ###########
# try three cluster numbers
for i in (2, 3, 4,5,6):
    # make list to store each rows label
    label=[0 for l in range(len(tdf))]

    # data, number of cluster, num local, max neighbor
    clarans_instance=clarans(tdfs, i, 6, 4)
    clarans_instance.process()
    clusters=clarans_instance.get_clusters()

    # make label
    for j in range(0, len(clusters), 1):
        for k in range(0, len(clusters[j]), 1):
            label[clusters[j][k]]=j
    print(label)

    score=silhouette_score(tdfs, label)
    print(i, 'clusters silhouette score :', score)

    makePlt23(tdf, label, i)
plt.figure(figsize=(15,15))	
plt.show()