# -*- coding: utf-8 -*-
"""Maxabs_envi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lascjPEKCw9BRftg-1CMkp-GDLsGrf_y
"""

!pip install pyclustering

df = pd.read_csv('/content/drive/MyDrive/머신러닝/housing.csv')
from matplotlib import pyplot as plt
from sklearn.metrics import accuracy_score
import pandas as pd
import numpy as np
from sklearn import preprocessing
import warnings ; warnings.filterwarnings('ignore')
import seaborn as sns
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score
from sklearn import preprocessing
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
import sys
from sklearn.metrics import silhouette_score
from matplotlib import pyplot as plt
from pyclustering.cluster.clarans import clarans


mhv=df['median_house_value']
df.drop('median_house_value',axis=1, inplace=True)
# fill nan value in total_bedrooms
df.fillna(0, inplace=True)


roomDF=df[['total_rooms', 'total_bedrooms']]
whereDF=df[['longitude', 'latitude', 'ocean_proximity']]
specDF=df[['housing_median_age', 'total_rooms', 'total_bedrooms', 'ocean_proximity']]
enviDF=df[['population', 'households']]

sc=preprocessing.MaxAbsScaler()
enc=preprocessing.OrdinalEncoder()

op=enc.fit_transform(whereDF['ocean_proximity'].to_numpy().reshape(-1, 1))
whereDF['ocean_proximity']=op
tdf=enviDF[0:1000]
#tdf=tdf.drop('ocean_proximity', axis=1)
print(tdf)
tdfs=sc.fit_transform(tdf)
tdfs=tdfs.tolist()

# need dataframe, list of label, number of clusters
def makePlt2(df, label, k):
    # list for store feature data for each cluster
    store = [[[] for col in range(len(df.columns))] for row in range(k)]

    for m in range(len(label)):
        for n in range(i):
            if(label[m]==n):
                for o in range(len(tdf.columns)):
                    store[n][o].append(tdf.iloc[m:m+1, o:o+1].values[0][0])

    plt.subplot(230 + (k - 1))
    plt.xlabel(df.columns[0])
    plt.ylabel(df.columns[1])

    c = ['b.', 'r.', 'g.', 'y.', 'c.', 'm.']
    for p in range(k):
        plt.plot(store[p][0], store[p][1], c[p])

########## clarans ###########
# try three cluster numbers
for i in (2, 3, 4, 5, 6):
    # make list to store each rows label
    label=[0 for l in range(len(tdf))]

    # data, number of cluster, num local, max neighbor
    clarans_instance=clarans(tdfs, i, 6, 4)
    clarans_instance.process()
    clusters=clarans_instance.get_clusters()

    # make label
    for j in range(0, len(clusters), 1):
        for k in range(0, len(clusters[j]), 1):
            label[clusters[j][k]]=j
    print(label)

    score=silhouette_score(tdfs, label)
    print(i, 'clusters silhouette score :', score)

    makePlt2(tdf, label, i)

plt.show()