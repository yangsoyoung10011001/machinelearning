{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOINGgL8QAOLtV7aH277+6w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yangsoyoung10011001/machinelearning/blob/main/cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmNbt-YyXmvv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import warnings ; warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold \n",
        "skf = StratifiedKFold(n_splits=10) \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sys\n",
        "################\n",
        "#make result table\n",
        "score_sample = {'Scaler':[\"Sample\"], 'Encoder':[\"Sample\"], 'Model':[\"Sample\"],'Best_para':[\"Sample\"], \"Score\":[1]}\n",
        "score_results = pd.DataFrame(score_sample)\n",
        "\n",
        "\n",
        "\n",
        "#for scale and encorde\n",
        "class PreprocessPipeline(): \n",
        "    def __init__(self, num_process, cat_process, verbose=False): \n",
        "        #super(PreprocessPipeline, self).__init__() \n",
        "        self.num_process = num_process \n",
        "        self.cat_process = cat_process \n",
        "        #for each type\n",
        "        if num_process == 'standard': \n",
        "            self.scaler = preprocessing.StandardScaler() \n",
        "        elif num_process == 'minmax': \n",
        "            self.scaler = preprocessing.MinMaxScaler() \n",
        "        elif num_process == 'maxabs': \n",
        "            self.scaler = preprocessing.MaxAbsScaler() \n",
        "        elif num_process == 'robust': \n",
        "            self.scaler = preprocessing.RobustScaler() \n",
        "        else: \n",
        "            raise ValueError(\"Supported 'num_process' : 'standard','minmax','maxabs','robust'\")   \n",
        "        if cat_process == 'onehot': \n",
        "            self.encoder = preprocessing.OneHotEncoder(sparse=False, handle_unknown='ignore')  \n",
        "        elif cat_process == 'ordinal': \n",
        "            self.encoder = preprocessing.OrdinalEncoder() \n",
        "        else: \n",
        "            raise ValueError(\"Supported 'cat_process' : 'onehot', ordinal'\") \n",
        "\n",
        "        self.verbose=verbose \n",
        "        \n",
        "        #do Preprocess\n",
        "    def process(self, X, Xt): #Xtest\n",
        "        X_cats = X.select_dtypes(np.object).copy() \n",
        "        X_nums = X.select_dtypes(exclude=np.object).copy() \n",
        "        Xt_cats = Xt.select_dtypes(np.object).copy() \n",
        "        Xt_nums = Xt.select_dtypes(exclude=np.object).copy() \n",
        "\n",
        "        if self.verbose: \n",
        "            print(f\"Categorica Colums : {list(X_cats)}\") \n",
        "            print(f\"Numeric Columns : {list(X_nums)}\") \n",
        "\n",
        "        if self.verbose: \n",
        "            print(f\"Categorical cols process method : {self.cat_process.upper()}\") \n",
        "\n",
        "        X_cats = self.encoder.fit_transform(X_cats) \n",
        "        Xt_cats = self.encoder.transform(Xt_cats) \n",
        "\n",
        "        if self.verbose: \n",
        "            print(f\"Numeric columns process method : {self.num_process.upper()}\") \n",
        "        X_nums = self.scaler.fit_transform(X_nums) \n",
        "        Xt_nums = self.scaler.transform(Xt_nums) \n",
        "\n",
        "        X_processed = np.concatenate([X_nums, X_cats], axis=-1) \n",
        "        Xt_processed = np.concatenate([Xt_nums, Xt_cats], axis=-1) \n",
        "     \n",
        "        return X_processed, Xt_processed \n",
        "\n",
        "# do process on I want \n",
        "class AutoProcess():\n",
        "    def __init__(self, verbose=False):\n",
        "        \n",
        "        self.pp = PreprocessPipeline\n",
        "        self.verbose= verbose\n",
        "    \n",
        "    def run(self, X, Y, Xt, Yt):\n",
        "        methods = []\n",
        "        scores = []\n",
        "        print(X.shape, Xt.shape)\n",
        "        \n",
        "        for num_process in ['standard','robust','minmax','maxabs']:\n",
        "            for cat_process in ['onehot','ordinal']:\n",
        "                if self.verbose:\n",
        "                    print(\"\\n------------------------------------------------------\\n\")\n",
        "                    print(f\"Numeric Process : {num_process}\")\n",
        "                    print(f\"Categorical Process : {cat_process}\")\n",
        "                methods.append([num_process, cat_process])\n",
        "\n",
        "                pipeline = self.pp(num_process=num_process, cat_process=cat_process)\n",
        "                \n",
        "                X_processed, Xt_processed = pipeline.process(X, Xt)\n",
        "\n",
        "                #Classifier part\n",
        "                for model in ['gini','entropy','svc']:\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nClassifier model: {model}\")\n",
        "\n",
        "                    if model =='gini': \n",
        "                        param_grid = {'max_depth' : [3,5,7,10],\n",
        "                                      \"min_samples_leaf\":[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "                                      \"min_samples_split\":[2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "                        clf = DecisionTreeClassifier()\n",
        "                    elif model =='svc':\n",
        "                        param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                                     'gamma': [0.001, 0.01, 0.1, 1, 10, 100] }\n",
        "                        clf = SVC()\n",
        "                    else:\n",
        "                        param_grid = {'max_depth' : [3,5,7,10],\n",
        "                                      \"min_samples_leaf\":[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "                                      \"min_samples_split\":[2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "                        clf = DecisionTreeClassifier(criterion = \"entropy\")\n",
        "\n",
        "                    grid_search = GridSearchCV(clf,param_grid,cv=5)\n",
        "                    grid_search.fit(X_processed,Y)\n",
        "                    score_results.loc[len(score_results)] = [num_process, cat_process, model, grid_search.best_params_, grid_search.best_score_]\n",
        "\n",
        "                    clf = clf.fit(X_processed, Y)  \n",
        "                    predict = clf.predict(Xt_processed)\n",
        "                    score1 = accuracy_score(Yt, predict)\n",
        "                    #print(\"Score: \", score1)\n",
        "\n",
        "                    score = cross_val_score(clf, Xt_processed, Yt, cv=kfold, n_jobs=1, scoring='accuracy')\n",
        "                    score2 = np.mean(score)\n",
        "                    #print(\"Score with using kfold: \", score2)\n",
        "\n",
        "                    score_results.loc[len(score_results)] = [num_process, cat_process, model, np.NaN ,score1]\n",
        "                    score_results.loc[len(score_results)] = [num_process, cat_process, model+\" with kfold\",np.NaN, score2]\n",
        "                \n",
        "                #logistic Regression part\n",
        "                for model in ['logistic']:\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nRegression model: {model}\")\n",
        "                    \n",
        "                    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                                  'penalty': ['l1', 'l2']}\n",
        "                    grid_search =GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "                    grid_search.fit(X_processed, Y)\n",
        "                    \n",
        "                    #lr = LogisticRegression().fit(X_processed, Y)\n",
        "                    #predict = lr.predict(Xt_processed)\n",
        "                    #score = round(accuracy_score(Yt, predict.round())*100, 2)\n",
        "                    score_results.loc[len(score_results)] = [num_process, cat_process, model, grid_search.best_params_, grid_search.best_score_]\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "kfold = KFold(5, True, 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('E:\\PythonWorkSpace\\s2\\lab1\\\\breast-cancer-wisconsin.data', sep=',',names=['ID','CT','UC Size','UC Shape','MA','SECS','BN','BC','NN','Mitoses','Class'],header=None)\n",
        "#print(df)\n",
        "\n",
        "#check null\n",
        "print(df.isnull().sum())\n",
        "#check data type\n",
        "print(df.dtypes)\n",
        "df=df[df.BN != '?']\n",
        "df=df.astype({'BN':int})\n",
        "##print(df.dtypes)\n",
        "df = df.drop(['ID'],axis =1)\n",
        "print(df)\n",
        "\n",
        "#Separate taget and feature\n",
        "X =df.iloc[:,0:9]\n",
        "Y = df.iloc[:,[9]]\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "#split train and test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=0)\n",
        "\n",
        "\n",
        "autoprocess = AutoProcess(verbose=True)\n",
        "autoprocess.run(X_train, Y_train, X_test, Y_test)\n",
        "\n",
        "\n",
        "pd.set_option('display.max_row', 100)\n",
        "print(score_results.sort_values(by=['Score'], axis=0,ascending=False))\n",
        "sys.stdout = open('score result.txt', 'w')\n",
        "\n",
        "print(score_results.sort_values(by=['Score'], axis=0,ascending=False))\n",
        "\n",
        "sys.stdout.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}